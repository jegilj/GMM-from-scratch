{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JhWAo1KDW1N"
      },
      "source": [
        "# Práctica 10: interpretabilidad de modelos de clasificación\n",
        "\n",
        "En este notebook se muestra cómo crear mapas de activación para visualizar las decisiones tomadas por un modelo de clasificación de imágenes. Esta técnica está basada en el trabajo [\"Grad-CAM: Why Did You Say That? Visual Explanations from Deep Networks via Gradient-based Localization\"](https://arxiv.org/abs/1611.07450).\n",
        "\n",
        "Para ello vamos a reutilizar nuestro modelo de la práctica 1 creado con la librería [fastAI](https://www.fast.ai/).\n",
        "\n",
        "En esta práctica vamos a hacer un uso intensivo de la GPU, así que es importante activar su uso desde la opción Configuración del cuaderno del menú Editar (esta opción debería estar habilitada por defecto, pero es recomendable que lo compruebes).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYU0-zrcOh14"
      },
      "source": [
        "## Pasos previos\n",
        "\n",
        "En primer lugar debemos entrenar un modelo como vimos en la práctica 1. A continuación se dan los pasos explicados en dicha práctica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAuCn9J_Oh15"
      },
      "source": [
        "## Librerías\n",
        "\n",
        "Comenzamos descargando la última versión de la librería FastAI. Al finalizar la instalación deberás reiniciar el kernel (menú Entorno de ejecución -> Reiniciar Entorno de ejecución)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uj9Perd_G8yQ"
      },
      "outputs": [],
      "source": [
        "!pip install fastai --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNNOdP-COh16"
      },
      "source": [
        "A continuación, cargamos aquellas librerías que son necesarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xn1xZElYCgmf"
      },
      "outputs": [],
      "source": [
        "from fastai.vision.all import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2pdkIefOh17"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Para esta práctica vamos a usar como ejemplo de dataset el [Intel Image Classification dataset](https://www.kaggle.com/puneet6060/intel-image-classification). Este dataset consta de imágenes de tamaño 150x150 distribuidas en 6 categorías (buildings, forest, glacier, mountain, sea, street). Los siguientes comandos descargan y descomprimen dicho dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLtRq9ROOh18"
      },
      "outputs": [],
      "source": [
        "!wget https://unirioja-my.sharepoint.com/:u:/g/personal/joheras_unirioja_es/EbMVHqKMSnNHh6I0-4-QWdQBlVDKz2Uz5Ky73zc5tHGofg?download=1 -O IntelImageClassification.zip\n",
        "!unzip IntelImageClassification.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmCRwR-cOh18"
      },
      "source": [
        "Vamos a explorar el contenido de este dataset. Para ello vamos a crear un objeto [Path](https://docs.python.org/3/library/pathlib.html) que apunta al directorio que acabamos de crear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRvgyy-hOh19"
      },
      "outputs": [],
      "source": [
        "path = Path('IntelImageClassification/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg0u17RsOh19"
      },
      "source": [
        "Vemos que nuestro dataset consta de dos carpetas llamadas `train` y `test`. Recordar que es importante hacer la partición del dataset en dos conjuntos distintos, para luego poder evaluarlo correctamente. Podemos ahora crear objetos `path` que apunten respectivamente a nuestro conjunto de entrenamiento y a nuestro conjunto de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXysShXgOh1-"
      },
      "outputs": [],
      "source": [
        "trainPath = path/'train'\n",
        "testPath = path/'test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIQ2BMrPOh1-"
      },
      "source": [
        "## Cargando el dataset\n",
        "\n",
        "A continuación vamos a mostrar cómo se carga el dataset para poder posteriormente crear nuestro modelo. Este proceso se hace en dos pasos. Primero se construye un objeto `DataBlock` y a continuación se construye un objeto `DataLoader` a partir del `DataBlock`. Tienes más información sobre estos objetos en la documentación de [FastAI](https://docs.fast.ai/tutorial.datablock.html).\n",
        "\n",
        "### Datablock\n",
        "\n",
        "Comenzamos construyendo el objeto `DataBlock`. A continuación explicaremos cada una de sus componentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwNs0airOh1-"
      },
      "outputs": [],
      "source": [
        "db = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
        "                 get_items=get_image_files,\n",
        "                 splitter=RandomSplitter(valid_pct=0.2,seed=42),\n",
        "                 get_y=parent_label,\n",
        "                 item_tfms = Resize(256),\n",
        "                 batch_tfms=aug_transforms(size=128,min_scale=0.75))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRBcctD3Oh1_"
      },
      "source": [
        "### Dataloader\n",
        "\n",
        "Pasamos ahora a construir nuestro `DataLoader` que se construye a partir del `DataBlock` construido anteriormente indicándole el path donde se encuentran nuestras imágenes. Además podemos configurar el `DataLoader` indicándole el tamaño del batch que queremos utilizar. Al trabajar con GPUs es importante que usemos batches de tamaño 2^n para optimizar el uso de la GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyRrTSQQOh1_"
      },
      "outputs": [],
      "source": [
        "dls = db.dataloaders(trainPath,bs=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3nBUCRCOh1_"
      },
      "source": [
        "## Entrenando el modelo\n",
        "\n",
        "Pasamos ahora a construir y entrenar nuestro modelo. Pero antes vamos a definir una serie de *callbacks*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJt0mPFBOh1_"
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    ShowGraphCallback(),\n",
        "    EarlyStoppingCallback(patience=3),\n",
        "    SaveModelCallback(fname='modelResnet18')\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KStetUCoOh2A"
      },
      "source": [
        "Además de estos tres callbacks utilizaremos otro que nos servirá para acelerar el entrenamiento de nuestros modelos usando [*mixed precision*](https://docs.fast.ai/callback.fp16.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtWPhKV6Oh2A"
      },
      "source": [
        "## Construyendo el modelo\n",
        "\n",
        "A continuación construimos nuestro modelo, un objeto de la clase `Learner`, utilizando el método `cnn_learner` que toma como parámetros el `DataLoader`, la arquitectura que queremos entrenar (en nuestro caso un `resnet18`), la métrica que usaremos para evaluar nuestro modelo (esta evaluación se hace sobre el conjunto de validación, y en nuestro caso será la *accuracy*), y los callbacks. Notar que en la instrucción anterior incluimos la transformación del modelo a *mixed precision*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65ikPqHAOh2A"
      },
      "outputs": [],
      "source": [
        "learn = vision_learner(dls,resnet18,metrics=accuracy,cbs=callbacks).to_fp16()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMLibjppQcNt"
      },
      "outputs": [],
      "source": [
        "learn.fine_tune(10,base_lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQoSzWlVOh2A"
      },
      "source": [
        "## Gradient CAM\n",
        "\n",
        "El mapa de activación de clases (en inglés, *class activation map* o CAM) usa la salida de la última capa confolucional junto con las predicciones del modelo para producir un mapa de valor que nos ayuda a visualizar porqué el modelo tomo la decisión.\n",
        "\n",
        "Para construir los mapas de activación, vamos a necesitar acceder a las activaciones dentro del modelo. Para ello vamos a usar los `hooks` que permiten introducir código en los calculos de propagación hacia adelante y hacia atrás del modelo. Es posible agregar un hook a cualquier capa del modelo, y este será ejecutado al calcular las salidas (*forward hook*) o durante el proceso de backpropagation (*backward hook*). Un forward hook es una función que toma tres cosas: un modulo (la arquitectura de la red), la entrada del modulo y su salida. Definimos a continuación dos hooks (uno forward y otro backward) que nos permitirán acceder a las activaciones del modelo. Una descripción más detallada de estos hooks puede verse en la [librería FastAI](https://github.com/fastai/fastbook/blob/master/18_CAM.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfLDIKfGOh2B"
      },
      "outputs": [],
      "source": [
        "class Hook():\n",
        "    def __init__(self, m):\n",
        "        self.hook = m.register_forward_hook(self.hook_func)\n",
        "    def hook_func(self, m, i, o): self.stored = o.detach().clone()\n",
        "    def __enter__(self, *args): return self\n",
        "    def __exit__(self, *args): self.hook.remove()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovKs-Fb2Oh2B"
      },
      "outputs": [],
      "source": [
        "class HookBwd():\n",
        "    def __init__(self, m):\n",
        "        self.hook = m.register_backward_hook(self.hook_func)\n",
        "    def hook_func(self, m, gi, go): self.stored = go[0].detach().clone()\n",
        "    def __enter__(self, *args): return self\n",
        "    def __exit__(self, *args): self.hook.remove()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "176ULlKBOh2B"
      },
      "source": [
        "A continuación elegimos la clase de la cual queremos extraer el mapa de activación. Para ello vamos a cargar una imagen, lo cargamos como un batch de datos, y vemos la predicción devuelta por el modelo, y utilizar dicha clase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaelkTmlOh2B"
      },
      "outputs": [],
      "source": [
        "img = PILImage.create('IntelImageClassification/test/mountain/20058.jpg')\n",
        "x, = first(dls.test_dl(['IntelImageClassification/test/mountain/20058.jpg']))\n",
        "print(learn.predict('IntelImageClassification/test/mountain/20058.jpg'))\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ_4GKpgOh2B"
      },
      "source": [
        "En este caso, la clase es montaña cuyo índice es 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJbO5TxTOh2C"
      },
      "outputs": [],
      "source": [
        "cls = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u36gqFzYOh2C"
      },
      "source": [
        "Ahora para la clase cuyo índice es 3 atrapamos los descriptores de la última capa convolucional y calculamos los gradientes de las salidas de activación de la clase montaña."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC6ATk5LOh2C"
      },
      "outputs": [],
      "source": [
        "with HookBwd(learn.model[0]) as hookg:\n",
        "    with Hook(learn.model[0]) as hook:\n",
        "        output = learn.model.eval()(x.cuda())\n",
        "        act = hook.stored\n",
        "    output[0,cls].backward()\n",
        "    grad = hookg.stored"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8Z7YV_KOh2C"
      },
      "source": [
        "Los pesos que nos interesan son la media de los gradientes de los descriptores, y esto lo podemos calcular del siguiente modo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSjVqRWxOh2C"
      },
      "outputs": [],
      "source": [
        "w = grad[0].mean(dim=[1,2], keepdim=True)\n",
        "cam_map = (w * act[0]).sum(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ua8Rft7Oh2C"
      },
      "source": [
        "Por último podemos visualizar el mapa del calor usando el siguiente código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FutlvAazOh2C"
      },
      "outputs": [],
      "source": [
        "x_dec = TensorImage(dls.train.decode((x,))[0][0])\n",
        "_,ax = plt.subplots()\n",
        "x_dec.show(ctx=ax)\n",
        "ax.imshow(cam_map.detach().cpu(), alpha=0.6, extent=(0,x.shape[2],x.shape[3],0),\n",
        "              interpolation='bilinear', cmap='magma');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toNI20DkOh2D"
      },
      "source": [
        "Es posible hacer lo mismo no solo con la última capa convolucional de la red, sino con cualquier otra de las capas, por ejemplo con la penultima capa del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyyAei-MOh2D"
      },
      "outputs": [],
      "source": [
        "with HookBwd(learn.model[0][-2]) as hookg:\n",
        "    with Hook(learn.model[0][-2]) as hook:\n",
        "        output = learn.model.eval()(x.cuda())\n",
        "        act = hook.stored\n",
        "    output[0,cls].backward()\n",
        "    grad = hookg.stored\n",
        "\n",
        "w = grad[0].mean(dim=[1,2], keepdim=True)\n",
        "cam_map = (w * act[0]).sum(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvonw7S8Oh2D"
      },
      "source": [
        "Y volvemos a realizar la visualización."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3Q5JsfwOh2D"
      },
      "outputs": [],
      "source": [
        "x_dec = TensorImage(dls.train.decode((x,))[0][0])\n",
        "_,ax = plt.subplots()\n",
        "x_dec.show(ctx=ax)\n",
        "ax.imshow(cam_map.detach().cpu(), alpha=0.6, extent=(0,x.shape[2],x.shape[3],0),\n",
        "              interpolation='bilinear', cmap='magma');"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fnnBS_i2mW02"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Practica10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}